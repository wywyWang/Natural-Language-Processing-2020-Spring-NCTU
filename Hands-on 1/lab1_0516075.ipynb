{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab1-0516075.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsQ_pHO3cG1m",
        "colab_type": "text"
      },
      "source": [
        "#Recommend Similar News Articles\n",
        "This notebook demonstrates how to use bag-of-word vectors and cosine similarity for news article recommendation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B80ijUN40QPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJH61jnWXdsh",
        "colab_type": "text"
      },
      "source": [
        "#Fetching the Corpus\n",
        "`get_corpus()` reads the CSV file, and then return a list of the news headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwPf9e26O9sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_corpus():\n",
        "  df = pd.read_csv('https://raw.githubusercontent.com/bshmueli/108-nlp/master/reuters.csv') # https://bit.ly/nlp-reuters\n",
        "  print(\"Dataset columns\", df.columns)\n",
        "  print(\"Dataset size\", len(df))\n",
        "  # Use content instead of title\n",
        "  corpus = df.content.to_list()\n",
        "  title = df.title.to_list()\n",
        "  # Process stopwords into list\n",
        "  stopword = pd.read_csv('https://raw.githubusercontent.com/bshmueli/108-nlp/master/stopwords.txt', header=None).values.tolist()\n",
        "  stopword = [_[0] for _ in stopword]\n",
        "  return title, corpus, stopword, len(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arntcI3OTHTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(document):\n",
        "  # Remove punctuation, and convert all tokens to lowercase\n",
        "  words = re.split('\\W+', document.lower())[:-1]\n",
        "  # Remove stopwords\n",
        "  words = [_ for _ in words if _ not in stopword]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4lh_w1HXU14",
        "colab_type": "text"
      },
      "source": [
        "#Computing word frequencies\n",
        "`get_vocab(corpus)` computes the word frequencies in a given corpus. It returns a list of 2-tuples. Each tuple contains the token and its frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJvtr3VZLkAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vocab(corpus):\n",
        "  vocabulary = Counter()\n",
        "  for document in corpus:\n",
        "    tokens = tokenize(document)\n",
        "    vocabulary.update(tokens)\n",
        "  return vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwy_Cb-9cYwe",
        "colab_type": "text"
      },
      "source": [
        "#Compute TF-IDF Vector\n",
        "`doc_to_vec(doc, vocab)` returns a TFIDF vector for document `doc`, corresponding to the presence of a word in `vocab`  \n",
        "`compute_idf(vocab, corpus)` returns a IDF vector for counting frequencies in all document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXiNzKTxXKEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_idf():\n",
        "  idf_vec = []\n",
        "  for token, freq in vocab:\n",
        "    appear = 0\n",
        "    for doc in corpus:\n",
        "      doc_tokens = tokenize(doc)\n",
        "      if token in doc_tokens:\n",
        "        appear += 1\n",
        "    idf_vec.append(math.log(N / appear))\n",
        "  return idf_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZv_zSh2WtPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc2vec(doc):\n",
        "  doc_tokens = tokenize(doc)\n",
        "  # Compute tf vectors\n",
        "  tf_vec = []\n",
        "  for token, freq in vocab:\n",
        "    tf_vec.append(doc_tokens.count(token))\n",
        "  tf_vec = [float(_) / sum(tf_vec) for _ in tf_vec]\n",
        "  # Compute tf-idf vectors\n",
        "  tfidf_vec = [tf * idf for tf, idf in zip(tf_vec, idf_vec)]\n",
        "  return tfidf_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q3bc4T_kzMy",
        "colab_type": "text"
      },
      "source": [
        "Cosine similarity between two numerical vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WuWEBWLQBAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(vec_a, vec_b):\n",
        "  assert len(vec_a) == len(vec_b)\n",
        "  if sum(vec_a) == 0 or sum(vec_b) == 0:\n",
        "    return 0 # hack\n",
        "  a_b = sum(i[0] * i[1] for i in zip(vec_a, vec_b))\n",
        "  a_2 = sum([i * i for i in vec_a])\n",
        "  b_2 = sum([i * i for i in vec_b])\n",
        "  return a_b/(math.sqrt(a_2) * math.sqrt(b_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FEyKg0mkeLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc_similarity(doc_a, doc_b):\n",
        "  return cosine_similarity(doc2vec(doc_a), doc2vec(doc_b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddRwu-O1f13Q",
        "colab_type": "text"
      },
      "source": [
        "# Find Similar Documents\n",
        "Find and print the $k$ most similar titles to a given title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6rIkWUrmhxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_similar(seed_id, k):\n",
        "  seed_doc = corpus[seed_id]\n",
        "  print('> \"{}\"'.format(title[seed_id]))\n",
        "  similarities = [doc_similarity(seed_doc, doc) for id, doc in enumerate(corpus)]\n",
        "  top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[-k:] # https://stackoverflow.com/questions/13070461/get-indices-of-the-top-n-values-of-a-list\n",
        "  nearest = [[title[id], similarities[id]] for id in top_indices]\n",
        "  print()\n",
        "  for story in reversed(nearest):\n",
        "    print('* \"{}\" ({})'.format(story[0], story[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgPZe4rxUVPQ",
        "colab_type": "text"
      },
      "source": [
        "# Test our program\n",
        "\n",
        "- Global variables\n",
        "  - title, corpus, stopword, N, vocab, idf_vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjW8MQXZUmJU",
        "colab_type": "code",
        "outputId": "afe26f20-5cc6-47c0-a9a6-67bbb513fb57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "SELECTED_CORPUS = 75\n",
        "title, corpus, stopword, N = get_corpus()\n",
        "vocab = get_vocab(corpus).most_common(1000)\n",
        "idf_vec = compute_idf()\n",
        "k_similar(SELECTED_CORPUS, 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset columns Index(['title', 'content'], dtype='object')\n",
            "Dataset size 5354\n",
            "> \"Twitter CEO calls company ’people’s news network’\"\n",
            "\n",
            "* \"Twitter CEO calls company ’people’s news network’\" (1.0000000000000002)\n",
            "* \"Salesforce still mulls bid for Twitter as shareholders resist: sources\" (0.7203539245853299)\n",
            "* \"Twitter’s video-sharing mobile app Vine to close\" (0.6497663428296279)\n",
            "* \"No partner in sight, Twitter faces tough solo choices\" (0.6326379073769336)\n",
            "* \"Twitter adds WNBA games, news shows, concerts in try for live viewers\" (0.608258656476074)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}